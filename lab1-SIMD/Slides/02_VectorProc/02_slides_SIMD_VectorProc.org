#+STARTUP: showall indent
#  --- Use C-c C-c to reload this ---
#+TODO: TODO(t) | DONE(o)


# ### Hack to make title on several lines
#+BEAMER_HEADER: \title[HPP -- SIMD -- Vector]{High Performance Programming\\SIMD -- Vector Processors}
# #+BEAMER_HEADER: \subtitle{FISE2-INFO2\\ {\tiny Based on "Lecture 14: SIMD Processing", Prof. Onur Mutlu, Carnegie Mellon University, 2015}}
#+BEAMER_HEADER: \subtitle{FISE2-INFO2\\ {\tiny Based on "Lecture 14: SIMD Processing"\\Onur Mutlu, 2015}}
#+TITLE: High Performance Programming -- SIMD -- Vector Processors
#+AUTHOR: Guillaume MULLER
#+EMAIL: guillaume.muller@telecom-st-etienne.fr
#+DATE: \today
#+DESCRIPTION: High Performance Programming -- SIMD -- Vector Processors
#+KEYWORDS: High-Performance Programming SIMD Vector-Processors
#+LANGUAGE: en
#+OPTIONS: toc:nil      ## remove Table Of Content
#+OPTIONS: H:2          ## With H:1, *=slides || with H:2, *=sections
#+OPTIONS: num:nil  ## use itemize vs. enumerate
#+OPTIONS: comments yes

#+STARTUP: beamer
#+LATEX_CLASS: beamer

 # ### Conflicts withthe theme's color redefinition below :{
 # #+BEAMER_THEME: Warsaw
#+LATEX_HEADER: \usetheme{Warsaw}

 # ### Already loaded by org-mode
 # #+LATEX_HEADER: \usepackage[utf8]{inputenc}
 # #+LATEX_HEADER: \usepackage[T1]{fontenc}
 # #+LATEX_HEADER: \usepackage{graphicx}        % To insert images
 # #+LATEX_HEADER: \usepackage[normalem]{ulem}  % For underline/strike
 # #+LATEX_HEADER: \usepackage{amsmath}         % For mathcal?
 # #+LATEX_HEADER: \usepackage{amssymb}         % For math symbols?
 # #+LATEX_HEADER: \usepackage{hyperref}        % For pdf meta info + links?
 # #+LATEX_HEADER:  \hypersetup{
 # #+LATEX_HEADER:   pdfauthor={...},
 # #+LATEX_HEADER:   pdftitle={...},
 # #+LATEX_HEADER:   pdfkeywords={...},
 # #+LATEX_HEADER:   pdfsubject={...},
 # #+LATEX_HEADER:   pdfcreator={Emacs (Org mode)},
 # #+LATEX_HEADER:   pdflang={English}
 #  #+LATEX_HEADER: }

#+LATEX_HEADER: \hypersetup{
#+LATEX_HEADER:   colorlinks=true,%
#+LATEX_HEADER:   urlcolor=blue,%
#+LATEX_HEADER:   linkcolor=blue%
#+LATEX_HEADER: }

#+LATEX_HEADER: \usepackage[gen]{eurosym}    % For â‚¬ symbol
#+LATEX_HEADER: \usepackage{wasysym}         % For smileys
#+LATEX_HEADER: \usepackage{bclogo}          % For bcattention & bccrayon signs
#+LATEX_HEADER: \usepackage{fontawesome}     % For pretty UTF-8 emojis \faWarning \faExclamationTriangle
#+LATEX_HEADER: \usepackage{tikz}            % For drawings
#+LATEX_HEADER: \usetikzlibrary{arrows.meta} % For arrow heads
#+LATEX_HEADER: \usetikzlibrary{shadows}
#+LATEX_HEADER: \usepackage{tikzsymbols}     % For Sticky man
#+LATEX_HEADER: \usepackage{listings}        % To insert Java code listing
#+LATEX_HEADER: \definecolor{dkgreen}{rgb}{0,0.6,0}  %% Colors for the Java listings
#+LATEX_HEADER: \definecolor{gray}{rgb}{0.5,0.5,0.5}
#+LATEX_HEADER: \definecolor{mauve}{rgb}{0.58,0,0.82}
#+LATEX_HEADER: \lstset{frame=none,          % For Java listings
#+LATEX_HEADER:   language=C,
#+LATEX_HEADER:   aboveskip=1mm,
#+LATEX_HEADER:   belowskip=1mm,
#+LATEX_HEADER:   showstringspaces=false,
#+LATEX_HEADER:   columns=flexible,
#+LATEX_HEADER:   basicstyle={\scriptsize \ttfamily},
#+LATEX_HEADER:   numbers=left,
#+LATEX_HEADER:   numberstyle=\scriptsize\color{gray},
#+LATEX_HEADER:   keywordstyle=\color{blue},
#+LATEX_HEADER:   commentstyle=\color{dkgreen},
#+LATEX_HEADER:   stringstyle=\color{mauve},
#+LATEX_HEADER:   breaklines=true,
#+LATEX_HEADER:   breakatwhitespace=true,
#+LATEX_HEADER:   tabsize=2
#+LATEX_HEADER: }

  # Dark theme based on Warsaw
#+LATEX_HEADER: \setbeamercolor{normal text}{fg=white,bg=black!90}
#+LATEX_HEADER: \setbeamercolor{structure}{fg=white} %% TODO Problem with "description" env!
#+LATEX_HEADER: \setbeamercolor{alerted text}{fg=red!85!black}
#+LATEX_HEADER: \setbeamercolor{item projected}{use=item,fg=black,bg=item.fg!35}
#+LATEX_HEADER: \setbeamercolor*{palette primary}{use=structure,fg=structure.fg}
#+LATEX_HEADER: \setbeamercolor*{palette secondary}{use=structure,fg=structure.fg!95!black}
#+LATEX_HEADER: \setbeamercolor*{palette tertiary}{use=structure,fg=structure.fg!90!black}
#+LATEX_HEADER: \setbeamercolor*{palette quaternary}{use=structure,fg=structure.fg!95!black,bg=black!80}
#+LATEX_HEADER: \setbeamercolor*{framesubtitle}{fg=white}
#+LATEX_HEADER: \setbeamercolor*{block title}{parent=structure,bg=black!60}
#+LATEX_HEADER: \setbeamercolor*{block body}{fg=black,bg=black!10}
#+LATEX_HEADER: \setbeamercolor*{block title alerted}{parent=alerted text,bg=black!15}
#+LATEX_HEADER: \setbeamercolor*{block title example}{parent=example text,bg=black!15}

  # What is the "headline" level that is transformed to a frame?
#+LATEX_HEADER_FRAME_LEVEL: 1
#+LATEX_HEADER: \setbeamertemplate{navigation symbols}{}
#+LATEX_HEADER: \setbeamertemplate{headline}{}
#+LATEX_HEADER: \addtobeamertemplate{navigation symbols}{}{%
#+LATEX_HEADER:   \usebeamerfont{footline}%
#+LATEX_HEADER:   \usebeamercolor[fg]{footline}%
#+LATEX_HEADER:   \hspace{1em}%
#+LATEX_HEADER:   \insertframenumber{}/\inserttotalframenumber{}
#+LATEX_HEADER: }

  # Put a slide with presentation outline before every new section
#+LATEX_HEADER: \AtBeginSection[]
#+LATEX_HEADER: {
#+LATEX_HEADER:   \begin{frame}<beamer>
#+LATEX_HEADER:     %\frametitle{Outline for section \thesection}
#+LATEX_HEADER:     \tableofcontents[currentsection]
#+LATEX_HEADER:   \end{frame}
#+LATEX_HEADER: }

  # Make items appear one after the other
  # #+BEAMER: \beamerdefaultoverlayspecification{<+->}


#+LATEX_HEADER: \newcommand{\myarrow}[6]{ % size / src / linestyle / text / arrowhead / dest
#+LATEX_HEADER:   \begin{tikzpicture}[baseline=-0.5ex]{
#+LATEX_HEADER:       \node[inner sep=0](@1) at (0,0) {#2};
#+LATEX_HEADER:       \node[inner sep=0](@2) at (#1,0) {#6};
#+LATEX_HEADER:       \draw [#3,arrows={#5},shorten >= 2pt,shorten <= 2pt] (@1) -- (@2) node[pos=.5,above,inner sep=1pt] { #4 };}
#+LATEX_HEADER: \end{tikzpicture}\xspace
#+LATEX_HEADER: }

#+LATEX_HEADER: \def\up#1{$^\text{#1}$}
#+LATEX_HEADER: \newcommand{\FrFlag}{\includegraphics[height=1.5em]{../images/UML/Lecture1/flag_france.png}}
#+LATEX_HEADER: \newcommand{\LOTRing}{\includegraphics[height=1.5em]{../images/UML/Lecture1/LOTR_1Ring.png}}


  # ### One can include other org files with:
  # #+INCLUDE: "/path/to/chapter2.org" :minlevel 1

* Intro

** Readings
*** Paper1
    + [[https://people.cs.umass.edu/~emery/classes/cmpsci691st/readings/Arch/gpu.pdf][\textsc{Lindholm} /et al./, "NVIDIA Tesla: A Unified Graphics and Computing Architecture", IEEE Micro 2008.]]
*** Paper2
    + [[https://www.researchgate.net/publication/220422248_A_closer_look_at_GPUs/link/550041e60cf204d683b34481/download][\textsc{Fatahalian} and \textsc{Houston}, "A Closer Look at GPUs", CACM 2008.]]


** Reminder Intel Architecture
   [[./images/slides_SIMD_08_small.png]]
*** Reference
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:END:
+ \small [[https://users.ece.cmu.edu/~omutlu/pub/mutlu_hpca03.pdf][Mutlu /et al./, Runhead Execution, 2003]]


** Reminder Alpha Architecture
   [[./images/slides_SIMD_09_small.png]]
*** Reference
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:END:
+ \small [[https://www.cis.upenn.edu/~milom/cis501-Fall09/papers/Alpha21264.pdf][Kessler, "The Alpha 21264 Microprocessor", IEEE Micro, March-April 1999.]]


** SIMD: Exploiting Regular (Data) Parallelism
*** [[https://course.ece.cmu.edu/~ece447/s13/lib/exe/fetch.php?media=01447203.pdf][Flynn's Taxonomy of Computers]] (*1966*)
    + SISD: Single Instruction operates on Single Data
      \pause
    + *SIMD*: Single Instruction operates on Multiple Data
      + Array processor
      + Vector processor
      \pause
    + MISD: Multiple Instructions operate on Single Data
      + (rare)
      \pause
    + MIMD: Multiple Instructions operate on Multiple Data
      + Multi-Processor
      + Multi-Threaded


** Data Parallelism
*** Concurrency Model
    + *Same* operations *different* pieces of data
      + *SIMD*
      + E.g. dot product of 2 vectors
      + Instruction (operation) level
\pause
*** $\neq$ Threads
    + "Control" parallelism
\pause
*** $\neq$ Data Flow
    + (pipelines, branch prediction\ldots{})
    + $\neq$ operations in parallel


** SIMD Parallelism
*** Parallelism in *Time*
    + *Array* processors
      + 1 Instruction on multiple data
      + at the *same time*
      + using *different spaces*
\pause
*** Parallelism in *Space*
    + *Vector* processor
      + 1 Instruction on multiple data
      + using the *same space*
      + in *consecutive time steps*


** Array vs. Vector Processors
*** Code
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_COL: .22
:BEAMER_ENV: block
:END:
#+BEGIN_SRC asm
LD VR <- A[3:0]
ADD VR <- VR, 1
MUL VR <- VR, 2
ST  A[3:0] <- VR
#+END_SRC
\pause
*** Execution
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_COL: .77
:BEAMER_ENV: block
:END:
[[./images/slides_SIMD_19_small.png]]



** Array Processors
*** Array processors
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_ENV: block
:END:
+ Single operation on multiple (different) data elements
\pause

*** @@l: ~~@@
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:END:
 [[./images/slides_SIMD_21_small.png]]


** Vector Processors
*** Vector processor
+ Operates on /vectors/ not /scalars/
+ Scalar = Single value
+ Vector = 1D array of numbers
  + Used in many scientific apps
    #+BEGIN_SRC C
      for (i = 0; i<=49; i++) {
        C[i] = (A[i] + B[i]) / 2
      }
    #+END_SRC
\pause
*** Basic requirements
+ *vector* registers
+ *VLEN* (vector /length/ register)
+ *VSTR* (vector /stride/ register)
  + Stride: distance between two elements of a vector


** Vector Processors
*** Vector Processors & Pipelines
+ A vector instruction = each element in consecutive cycles
+ Vector functional units are *pipelined*
+ Each pipeline stage operates on a different data element
*** Vector Processors Advantages
+ *No* intra-vector *dependencies*
  + $\Rightarrow$ no hardware interlocking
+ *No control flow* within a vector
+ Known stride
  + $\Rightarrow$ *prefetching*


** Vector Processor Advantages
*** *No dependencies* within a vector
  + Pipelining, parallelization work well
  + Can have very deep pipelines, no dependencies!

*** Each instruction generates a lot of work
  + *Reduces instruction fetch* bandwidth requirements

*** Highly *regular memory access pattern*
  + Can interleave vector data elements across multiple memory banks for higher memory bandwidth (to tolerate memory bank access latency)
  + Prefetching a vector is relatively easy

*** No need to explicitly code loops
  + *Fewer branches* in the instruction sequence


** Vector Processor Disadvantages

*** Regular Parallelism
 + Works (only) if parallelism is regular (data/SIMD parallelism)
   + = Vector operations
 + Very inefficient if parallelism is irregular
   + How about searching for a key in a linked list?

*** @@l:~~@@
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_ENV: block
:END:
[[https://courses.cs.washington.edu/courses/cse548/16wi/Fisher-VLIW.pdf][\begin{quote}
"To program a vector machine, the compiler or hand coder must *make the data structure in the code fit nearly exactly the regular structure built into the hardware*. That's hard to do in first place, and just as hard to change. One tweak, and the low-level code has to be *rewritten* by a very smart and dedicated programmer who knows the hardware and often the subtelties of the application area."
\end{quote}]] \hfill Fisher, 1983.

** Vector Processor Limitations

*** Memory
 + Memory (bandwidth) can become a bottleneck if:
   1. compute/memory operation balance is not maintained
   2. data is not mapped appropriately to memory banks


* Vector processors in depth

** Vector Registers

*** Vector control registers
+ \small VLEN, VSTR, VMASK

*** Vector Registers
+ \small Each vector data register holds N $\times$ M-bit values
+ \small Maximum VLEN can be N
  + Maximum number of elements stored in a vector register

*** Vector Mask Register (VMASK)
  + \small Indicates which elements of vector to operate on
  + \small Set by vector test instructions @@latex: \texttt{VMASK[i] = (Vk[i] == 0)}@@
    \vspace*{-1em}
  # #+BEGIN_SRC C
  # VMASK[i] = (Vk[i] == 0)
  # #+END_SRC
#+ATTR_LATEX: :width .85\textwidth
 [[./images/slides_SIMD_28_small.png]]


** Vector Functional Units
*** Pipelines
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_COL: .6
:BEAMER_ENV: block
:END:
+ Vector elements are independent
  + $\Rightarrow$ *Deep pipeline* control is easy
+ Using deep pipelines
  + $\Rightarrow$ *Fast clock cycle*
*** Example
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_COL: .39
:BEAMER_ENV: block
:END:
+ 6 stages multiply
+ =V1*V2 -> V3=
#+ATTR_LATEX: :width .55\textwidth
[[./images/slides_SIMD_29_small.png]]


** Vector Machine Organization (CRAY-1)

*** @@l:~~@@
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_COL: .60
:BEAMER_ENV: block
:END:
[[./images/slides_SIMD_30_small.png]]

*** @@l:~~@@
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_COL: .39
:BEAMER_ENV: block
:END:
+ [[https://www.eecg.utoronto.ca/~moshovos/ACA05/read/cray1.pdf][CRAY-1]], 1978
+ scalar & vector regs.
+ 8 $\times$ 64 elts / reg
+ 64 bit / elt
+ 16 memory banks
+ 8 $\times$ 64b scalar re.
+ 8 $\times$ 24b addr. reg.


** Loading/Storing Vectors from/to Memory

*** @@l:~~@@
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_ENV: block
:END:
+ Requires loading/storing multiple elements
+ Elements separated by a *constant* distance (stride)
  + Assume stride = 1 for now
+ If we can start the load of one element per cycle
  + Elements can be loaded in *consecutive cycles*
  + $\Rightarrow$ Can sustain a *throughput of 1 elt/cycle*
*** Question
+ How do we achieve this with a memory that takes more than 1 cycle to access?
\pause
+ $\Rightarrow$ *Bank the memory*
+ $\Rightarrow$ Interleave elements across banks


** Memory Banking

*** Memory Banking
+ Memory is divided into *independent banks*
+ But that *share* address and data *buses*
+ Can start and complete *1 bank access/cycle*
+ Can sustain *N parallel accesses* if all N go to different banks

*** @@l:~~@@
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_ENV: block
:END:
[[./images/slides_SIMD_32_small.png]]



** Vector Memory System

*** Vector Memory System

+ Next address = Previous address + Stride
+ If
  + stride = 1 &
  + consecutive elements interleaved across banks &
  +  number of banks >= bank latency
+ then can sustain *1 element/cycle*

*** @@l:~~@@
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_ENV: block
:END:
[[./images/slides_SIMD_33_small.png]]


** Scalar Code Example
*** C
#+BEGIN_SRC C
 for (i = 0; i<=49; i++) {
   C[i] = (A[i] + B[i]) / 2
 }
#+END_SRC
*** ASM (/number = latency/)
#+BEGIN_SRC asm
MOVI R0 = 50               ; 1
MOVA R1 = A                ; 1
MOVA R2 = B                ; 1
MOVA R3 = C                ; 1
X: LD R4 = MEM[R1++]       ; 11 ; auto-inc
LD R5 = MEM[R2++]          ; 11
ADD R6 = R4 + R5           ; 4
SHFR R7 = R6 >> 1          ; 1
ST MEM[R3++] = R7          ; 11
DECBNZ --R0, X             ; 2 ; decr + brch non-0
#+END_SRC
+ Number of *instructions*: *$304$*
+ Execution time: ??


** Scalar Code Execution Time (In Order)
*** 1 memory bank
+ First two loads in the loop cannot be pipelined
  + $\Rightarrow$ 2*11 cycles
+ $4 + 50*40 =$ *$2004$* cycles
\pause
*** *16* memory bank
+ First two loads in the loop can be pipelined
+ $4 + 50*30 =$ *$1504$* cycles
\pause
*** Why *16* banks?
\pause
+ 11 cycle memory access latency
+ 16 banks (>11 cycles)
  + Enough to overlap enough mem. op. to cover mem. latency


** Vectorizable Loops
*** @@l:~~@@
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_ENV: block
:END:
+ Loop is *vectorizable* if each iteration independent of others
*** C
#+BEGIN_SRC C
 for (i = 0; i<=49; i++) {
   C[i] = (A[i] + B[i]) / 2
 }
#+END_SRC
*** Vectorized ASM (/number = latency/)
#+BEGIN_SRC asm
MOVI VLEN = 50        ; 1
MOVI VSTR = 1         ; 1
VLD V0 = A            ; 11 + VLN-1
VLD V1 = B            ; 11 + VLN-1
VADD V2 = V0 + V1     ; 4  + VLN-1
VSHFR V3 = V2 >> 1    ; 1  + VLN-1
VST C = V3            ; 11 + VLN-1
#+END_SRC
+ Number of *instructions*: *$7$*
+ Execution time: ??


** Vectorized Code Performance -- No Chaining

*** @@l:~~@@
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_ENV: block
:END:
+ Assume no chaining (no vector data forwarding)
  + Output of a vector functional unit cannot be used as the direct input of another
  + The entire vector register needs to be ready before any element of it can be used as part of another operation
+ One memory port (one address generator)
+ 16 memory banks (word-interleaved)

*** @@l:~~@@
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_ENV: block
:END:
[[./images/slides_SIMD_37_small.png]]

+ $2+2*(11+49)+4+49+1+49+11+49 =$ *$285$* cycles


** Vector Chaining

*** Vector chaining
:PROPERTIES:
:BEAMER_ENV: block
:END:
+ Data forwarding from one vector functional unit to another

*** @@l:~~@@
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_ENV: block
:END:
[[./images/slides_SIMD_38_small.png]]


** Vectorized Code Performance -- With Chaining

*** @@l:~~@@
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_ENV: block
:END:
#+ATTR_LATEX: :width .8\textwidth
[[./images/slides_SIMD_39_small.png]]

*** @@l:~~@@
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_ENV: block
:END:
+ $1+1+11+49+11+49+11+49=$ *$182$* cycles
\pause
+ \small 2 first VLD cannot be pipelined?
  # 16 banks? 1 port!
+ \small VLD & VST cannot be pipelined?
  # 1 port!
# + \small Strong assumption: each memory bank has a single port
  # (memory bandwidth bottleneck)


** Vectorized Code Performance -- Multiple Ports

*** @@l:~~@@
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_ENV: block
:END:
#+ATTR_LATEX: :width .5\textwidth
[[./images/slides_SIMD_40_small.png]]

*** @@l:~~@@
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_ENV: block
:END:
+ $1+1+1+11+4+1+11+49 =$ *$79$* cycles
+ *$19 \times$* improvment!


** Discussions

*** What if #data elements > #elements in a vector register?
\pause
+ Idea: Break loops
  + Each iteration operates on #elements vector register
  + E.g., 527 data elements, 64-element VREGs
    + 8 iterations where VLEN = 64
    + 1 iteration where VLEN = 15 (need to change value of VLEN)
\pause
+ Called *"vector stripmining"*
\pause

*** What if vector data is not stored in a strided fashion in memory?
\pause
# (irregular memory access to a vector)
+ Idea: Use indirection
  + Combine/pack elements in vector registers
+ Called *"scatter/gather operations"*


** Gather/Scatter Operations
*** Vectorize loops with indirect accesses
#+BEGIN_SRC C
  for (i=0; i<N; i++) {
    A[i] = B[i] + C[D[i]]
  }
#+END_SRC
*** Indexed load intruction (Gather)
#+BEGIN_SRC asm
LV vD, rD         ; Load indices in D vector
LVI vC, rC, vD    ; Load indirect from rC base
LV vB, rB         ; Load B vector
ADDV.D vA,vB,vC   ; Do add
SV vA, rA         ; Store result
#+END_SRC

** Gather/Scatter Operations
*** @@l:~~@@
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_ENV: block
:END:
+ Gather/scatter often implemented in hardware
#  (sparse matrices)
+ Vector load/store addresses = base register + index vector

*** Example
:PROPERTIES:
:BEAMER_ENV: block
:END:
# |--------------+-------------+--------+---------------|
| Index Vector | Data Vector |        | Stored Vector |
|              |  (to store) |        | (in memory)   |
|            0 |        3.14 | Base+0 | 3.14          |
|            2 |         6.5 | Base+1 | x             |
|            6 |        71.2 | Base+2 | 6.5           |
|            7 |        2.71 | Base+3 | x             |
|              |             | Base+4 | x             |
|              |             | Base+5 | x             |
|              |             | Base+7 | 71.2          |
|              |             | Base+7 | 2.71          |
# |--------------+-------------+--------+---------------|


** Conditional Operations in a Loop
*** @@l:~~@@
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_ENV: block
:END:
+ What if some operations should not be executed on a vector?
# (based on a dynamically-determined condition)?
#+BEGIN_SRC C
  loop: if (a[i] != 0) {
     b[i] = a[i]*b[i];
  }
  goto loop
#+END_SRC
\pause
*** Masked Operations
+ VMASK register is a bit mask determining which data element should not be acted upon
#+BEGIN_SRC asm
VLD V0 = A
VLD V1 = B
VMASK = (V0 != 0)
VMUL V1 = V0 * V1
VST B = V1
#+END_SRC
# + Does this look familiar?
#   + This is essentially predicated execution.


** Another Example with Masking
*** C Code
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_COL: .35
:BEAMER_ENV: block
:END:
#+BEGIN_SRC C
  for (i = 0; i < 64; ++i) {
    if (a[i] >= b[i]) {
      c[i] = a[i];
    } else {
      c[i] = b[i];
    }
  }
#+END_SRC
\pause
*** @@l:~~@@
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:BEAMER_COL: .60
:BEAMER_ENV: block
:END:
\small
|  A |  B | VMASK |
|  1 |  2 |     0 |
|  2 |  2 |     1 |
|  3 |  2 |     1 |
|  4 | 10 |     0 |
| -5 | -4 |     0 |
|  0 | -3 |     1 |
|  6 |  5 |     1 |
| -7 | -8 |     1 |

*** 
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:END:
# TODO: remove the empty block!

*** Steps to execute the loop in SIMD code
:PROPERTIES:
:BEAMER_COL: 1
:BEAMER_ENV: block
:END:
1. *Compare A, B to get VMASK*
2. Masked store of A into C
3. Complement VMASK
4. Masked store of B into C


** Masked Vector Instructions
*** Simple Implementation
:PROPERTIES:
:BEAMER_COL: .49
:BEAMER_ACT: <1->
:BEAMER_ENV: block
:END:
- \small Do all computations
- \small Prevent writing of output
[[./images/slides_SIMD_46_small1.png]]

# @@latex: \begin{minipage}{c}{.49\textwidth}@@
*** @@l:~~@@
:PROPERTIES:
:BEAMER_COL: .49
:BEAMER_ACT: <2->
:BEAMER_OPT: ignoreheading
:END:
**** Density-Time Implementation
:PROPERTIES:
:BEAMER_ACT: <2->
:BEAMER_ENV: block
:END:
- Scan mask vector
- Only execute non-zero op
[[./images/slides_SIMD_46_small2.png]]

**** Comparison
:PROPERTIES:
:BEAMER_ACT: <3->
:BEAMER_ENV: block
:END:
- Which one is better?
- Trade-Offs?
  # Energy consumption > in first
  # Parallelism easier in first

# *** @@l:~~@@
# :PROPERTIES:
# :BEAMER_OPT: ignoreheading
# :END:
# @@latex: \end{minipage}@@



** Issues -- 1
*** Stride vs. Banking
+ To sustain 1 element/cycle throughput
  + #Banks & Bank latency must be *relatively prime*
  + Requires *enough banks* to cover bank access latency
+ Storage of a matrix
  + Row major vs. Column major (see next slide)
    # Row: Consecutive elements in a row are laid out consecutively in memory
    # Col: Consecutive elements in a column are laid out consecutively in memory
  + row $\rightarrow$ column $\Rightarrow$ *change the stride*


** Issues -- 2
:PROPERTIES:
:BEAMER_OPT: plain
:END:
 [[./images/slides_SIMD_48.png]]
# TODO: plain page?


** Minimizing Bank Conflicts
*** More banks
+ Adding Banks solves the problem, but \faDollar{}
\pause
*** Better data layout to match the access pattern
+ Is this always possible?
\pause
*** Better mapping of address to bank
+ E.g., [[https://people.eecs.berkeley.edu/~kubitron/courses/cs252-S12/handouts/papers/p74-rau.pdf][randomized mapping]]


** Automatic Code Vectorization
*** 
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:END:
#+BEGIN_SRC C
  for (i = 0; i<=49; i++) {
    C[i] = (A[i] + B[i]) / 2
  }
#+END_SRC

*** 
:PROPERTIES:
:BEAMER_OPT: ignoreheading
:END:
[[./images/slides_SIMD_55_small.png]]



** Vector/SIMD Processing Summary
*** *Data*-level parallelism
  + Same operation performed on many data elements
  + Improve performance, simplify design
  + No intra-vector dependencies
\pause
*** *Vectorizability* is the limit
  + Scalar operations limit vector machine performance
  + Remember [[https://en.wikipedia.org/wiki/Amdahl%27s_law][Amdahl's Law]]
# In computer architecture, Amdahl's law (or Amdahl's argument[1]) is a formula which gives the theoretical speedup in latency of the execution of a task at fixed workload that can be expected of a system whose resources are improved. It is named after computer scientist Gene Amdahl, and was presented at the AFIPS Spring Joint Computer Conference in 1967. 
  + CRAY-1 was the fastest *scalar* machine at its time!
\pause
*** *Current* situation
  + Many existing ISAs include (vector-like) SIMD operations
    + Intel MMX/SSE/AVX, ARM Advanced SIMD \ldots{}


** Vector Processors vs. Array Processors

*** *"purist's"* distinction
+ Array vs. vector processor distinction is a "purist's" distinction
\pause
*** *Current* situation
+ Most "modern" SIMD processors are a *combination of both*
  + They exploit data parallelism in both *time* and *space*
  + *GPUs* are a prime example
